{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organización de Datos (9558)\n",
    "\n",
    "## Trabajo Práctico N° 2\n",
    "\n",
    "#### Fecha: 2017-06-22\n",
    "\n",
    "#### Integrantes:\n",
    "\n",
    "\n",
    "#### Repo:\n",
    "[Github - TP2](https://github.com/frisjon/tp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*toc*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Enunciado\n",
    "\n",
    "El segundo TP es una competencia de Machine Learning en donde cada grupo debe intentar predecir la duración de los viajes en base a los datos de los mismos. La competencia se desarrolla en la plataforma de Kaggle, se provee un archivo \"train.csv\" que debe ser usado para entrenar un modelo de Machine Learning y un archivo \"test.csv\" que tiene los datos de los viajes a predecir. Adicionalmente pueden usarse los datos de las estaciones, del status de cada estación minuto a minuto y la información meteorológica.\n",
    "\n",
    "ADVERTENCIA MUY IMPORTANTE: Dado que los datos son públicos los resultados de la competencia ya se saben, son parte de los datos del TP1, es fundamental que ningún grupo suba a Kaggle submissions que usan esta información ya que distorsiona el score de la competencia y una vez subido un submission es IMPOSIBLE ELIMINARLO. Los submissions\n",
    "deben generarse en base a un modelo de machine learning y nunca en base a los resultados que ya se conocen.\n",
    "\n",
    "TL;DR: NO SUBIR A KAGGLE SUBMISSIONS QUE HACEN TRAMPA, ES IMPOSIBLE BORRARLOS!!!\n",
    "\n",
    "Los grupos deberán probar distintos algoritmos de Machine Learning para predecir la duración de los viajes en base a los datos de los mismos. A medida que los grupos realicen pruebas deben realizar el correspondiente submit en Kaggle para evaluar el resultado de los mismos. Al finalizar la competencia el grupo que mejor resultado tenga obtendrá 10 puntos para cada uno de sus integrantes que podrán ser usados en el examen por promoción o segundo recuperatorio.\n",
    "\n",
    "Requisitos para la entrega del TP2:\n",
    "1. El TP debe programarse en Python o R\n",
    "- Debe entregarse una carpeta con el informe de algoritmos probados, algoritmo final utilizado, transformaciones realizadas a los datos, feature engineering, etc.\n",
    "- El grupo debe presentar el TP en una computadora en la fecha indicada por la cátedra, el TP debe correr en un lapso de tiempo razonable (inferior a 1 hora) y generar un submission válido que iguale el mejor resultado obtenido por el grupo en Kaggle.\n",
    "\n",
    "El TP2 se va a evaluar en función del siguiente criterio:\n",
    "1. Cantidad de trabajo (esfuerzo) del grupo: ¿Probaron muchos algoritmos? ¿Hicieron un buen trabajo de pre-procesamiento de los datos y feature engineering?\n",
    "- Resultado obtenido en Kaggle (obviamente cuanto mejor resultado mejor nota)\n",
    "- Presentación final del informe, calidad de la redacción, uso de información obtenida en el TP1, conclusiones presentadas.\n",
    "- Performance de la solución final.\n",
    "\n",
    "\n",
    "ADVERTENCIA IMPORTANTE #2: Bajo ningún concepto debe interpretarse que es necesario finalizar el TP1 para poder comenzar el TP2, quienes incurran en este error se encontrarán que el tiempo necesario para desarrollar el TP2 es insuficiente. Es fundamental, imprescindible y vital comenzar el desarrollo del TP2 en forma paralela al TP1 para evitar problemas en el cumpimiento de las fechas de entrega."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### [Descipción](https://inclass.kaggle.com/c/san-francisco-biking)\n",
    "\n",
    "El propósito de esta competencia es predecir la duración de los viajes.\n",
    "\n",
    "El objetivo de esta competencia es predecir la duración de los viajes de acuerdo a los datos de los mismos, la información meteorológica, etc.\n",
    "\n",
    "Pueden usarse los siguientes archivos disponibles en:\n",
    "\n",
    "https://www.kaggle.com/benhamner/sf-bay-area-bike-share\n",
    "\n",
    "    .status\n",
    "    .station \n",
    "    .weather\n",
    "\n",
    "Para los viajes debe usarse el archivo train.csv provisto par entrenar el modelo y el archivo test.csv tiene los datos de los viajes a predecir.\n",
    "\n",
    "IMPORTANTE: El archivo trips.csv del TP anterior tiene los resultados que queremos predecir, estos resultados NO DEBEN usarse de ninguna forma para el entrenamiento del modelo. No subir a Kaggle ningún submission que sea generado a partir de estos datos ya que afecta la evaluación de la competencia y NO ES POSIBLE ELIMINAR SUBMISSIONS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### [Evaluación y Formato de Entrega](https://inclass.kaggle.com/c/san-francisco-biking/details/evaluation)\n",
    "\n",
    "La evaluación es por Mean Squared Error es decir la diferencia de cuadrados entre la duración real del viaje y la duración que se predice mediante el modelo de Machine Learning usado.\n",
    "\n",
    "El formato de submission es un archivo .csv de la forma:\n",
    "\n",
    "    id,duration\n",
    "    1,1\n",
    "    8,8\n",
    "    9,9 10\n",
    "    10,10 9\n",
    "    etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Conclusiones del TP 1\n",
    "\n",
    "> Los usuarios del serivicio, en su mayoria, lo utiliza para trasladarse al trabajo.\n",
    "\n",
    "> Ya conocemos cuáles son los datos a filtrar.\n",
    "\n",
    "> ... (agregar mas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Algunos comentarios sobre cosas en general (eliminar al terminar el tp)\n",
    "\n",
    "Hay que tener un modelo claro de cómo se resuelve el problema, hecho después de analizar los datos. (Esto es muy general. Después comento mas cosas sobre esto)\n",
    "\n",
    "Lo de Bagging y Bootstrapping va __al final__ porque es para ajustar el modelo lo mejor posible, claro esta, sin overfitting etc... Para que se pueda ajustar, el modelo tiene que estar definido e __implementado__. Yo creo que empezar algunas cosas sin tener una idea (bastante) clara, va a hacer el desarrollo mas lento.\n",
    "\n",
    "Planteo las siguientes preguntas para guiarnos y poder llegar a un acuerdo entre todos.\n",
    "\n",
    "> __Cómo es el algoritmo?__ Como es un problema de regresión (porque es, dar un número en un intervalo a partir de datos), usemos un algoritmo de regresión. [Wiki](https://es.wikipedia.org/wiki/An%C3%A1lisis_de_la_regresi%C3%B3n). \n",
    "\n",
    "> __Qué tipo de regresión?__ [Lineal](https://es.wikipedia.org/wiki/Regresi%C3%B3n_lineal) [MCO](https://es.wikipedia.org/wiki/M%C3%ADnimos_cuadrados_ordinarios) etc ... . Acá abría que ver los datos y como se comportan. Apliquemos métodos de reducción de dimensiones para no introducir ningún *bias*. Para esta parte, abría que considerar los datos que tenemos disponibles (mas sobre esto después)\n",
    "\n",
    "> __Qué tan útil puede ser tener otro tipo de algoritmos y por qué?__ (Clustering, etc) Por ejemplo clustering podría categorizar viajes en tiempos: largos, medianos, cortos.\n",
    "\n",
    "> __Ya existen algoritmos implementados que faciliten esto?__ Ver [Tensorflow](https://www.tensorflow.org/), [SciKit-Learn](http://scikit-learn.org/stable/index.html), R(?), ... (si conocen mas, comenten). De las que propongamos, __Cuál es la mas conveniente de usar y por qué?__\n",
    "\n",
    "> Sobre entrenar al algoritmo, hay que pensar de antemano, cuáles son los *features* que intuitivamente son importantes y justificar por qué lo son. Cuáles pueden traer problemas, por ejemplo, que tengan una importancia no debida (es decir que el algortimo aprenda que esos *features* sean importantes cuando creemos que no los son.) Ojo que esto podría mostrar patrones que no vemos a simple vista y que sí son importantes. Esto me parece importante de considerar para entender como operar con ciertos *features* en la implementacion o el modelo.\n",
    "\n",
    "> Considerando lo de *Reducción de dimensiones*, se me viene a la cabeza __SVD__. Claramente no podemos utilizar strings o fechas en ese formato. Entónces abría que hacer *One Hot Encoding*. (Las fechas por ejemplo se pueden pasar a [UNIX Time](https://es.wikipedia.org/wiki/Tiempo_Unix)). Luego de eso, lo que esperamos de la reducción es, ver en 2D (o 3D) cómo se distribuyen los datos, conservando distancias y eso. Con esto podemos proponer si el modelo de regresion es lineal, cuadratico, etc... . Además de considerar sólo a los datos en crudo, podemos introducir datos \"nuevos\", por ejemplo agregar información del clima, distancia entre estaciones, nombre (o código) de la *ciudad*, etc. y después, aplicar __SVD__. Propongo probar __TODAS__ las posibilidades que se nos ocurran mientras tengamos el tiempo de probar. Además, si se grafican esos datos, puede quedar lindo y eso. Volviendo al tema que quería comentar, al descomponer los datos en __SVD__, __Qué se obtiene exactamente?__ La teoría nos dice que tenemos en las primeras k columnas de U a los datos representados en k dimensiones. Cuidado que k no puede ser cualquier valor sino que sean algunos que preserven la *energia de la matriz* (p.317 del apunte)\n",
    "\n",
    "TLDR; \n",
    "\n",
    "Entender como se resuelve. Utilizamos perceptrones, etc?\n",
    "\n",
    "Analizar los datos y determinar qué features son importantes.\n",
    "\n",
    "Armar el modelo. (Cómo juntar los features)\n",
    "\n",
    "Probar lo de cross validation, etc\n",
    "\n",
    "---\n",
    "\n",
    "(Me parece que este orden de cómo ir avanzando, es el que vá. Propongan uds otras alternativas.) -mk\n",
    "\n",
    "Dudas que tengo y creo que se deben preguntar en clase o piazza:\n",
    "\n",
    "> Se puede *tocar* al set de *TEST*? (esto lo aclaro mas adelante. Lo dejo aca para que este ordenado :P )\n",
    "\n",
    "> Si se fijan el formato de archivo de entrega, hay algunas cosas que para mi estan mal o no lo entiendo.\n",
    "\n",
    "---\n",
    "\n",
    "Antes de seguir leyendo, podemos averiguar sobre cómo otras personas encaran este tipo de proyectos. Tal vez las preguntas se consteten de esa manera. \n",
    "\n",
    "[kernels de kaggle](https://www.kaggle.com/benhamner/sf-bay-area-bike-share/kernels)\n",
    "\n",
    "[papers](https://drive.google.com/drive/u/0/folders/0B8rBD4QSqWnSRDRFUkVDSnVMMFk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Introduciendo a la API\n",
    "\n",
    "[Tensorflow](https://www.tensorflow.org/get_started/get_started)\n",
    "\n",
    "(En el link, hay explicaciones de las estructuras utilizadas en tensorflow.) -mk\n",
    "\n",
    "(Asumiendo que utilizamos tensorflow, podemos armar un modelo basico.) -mk\n",
    "\n",
    "##### Ejemplo de una parte del modelo\n",
    "\n",
    "Un dato entra, separamos las partes (o dimensiones) que consideramos importantes, realizamos cálculos con ellos y devolvemos un resultado.\n",
    "\n",
    "Una parte del algoritmo (un *nodo* en tensorflow), podría tomar como parámetros a las id's de las estaciones y devolver la distancia entre ellas. Luego la distancia, irá por otras partes del modelo que serán utilizadas para determinar el resultado final que es la duración del viaje.\n",
    "\n",
    "(Acá van las consideraciones de la api, (que estructuras de datos estan disponibles, como se pueden utilizar y como las VAMOS a utilizar). Despues en __plan__, ya juntamos todas las consideraciones y formamos el plan) -mk\n",
    "\n",
    "---\n",
    "\n",
    "(__No__ se crean que la tengo clara con tensorflow!!1!!UNO!! (Me) Faltaria ver SK-Learn para comparar cual es mejor. Tambien considerar otras alternativas) -mk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Sets de Datos y (Feature Engineering | consideraciones)\n",
    "\n",
    "En esta sección analizamos los datos a modo de preparación de armado del modelo.\n",
    "\n",
    "Los sets de datos son:\n",
    "\n",
    ">[Entrenamiento y testeo](https://inclass.kaggle.com/c/san-francisco-biking/data) ( https://inclass.kaggle.com/c/san-francisco-biking/data )\n",
    "\n",
    ">[Set de datos del TP1](https://www.kaggle.com/benhamner/sf-bay-area-bike-share) (excluyendo a trips.csv) ( https://www.kaggle.com/benhamner/sf-bay-area-bike-share )\n",
    "\n",
    "\n",
    "*comentarios de SVD/PCA*\n",
    "\n",
    "*etc*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__(quitar esta sección. Está sólo para aclarar los métodos para obtener una mejor performance en tanto a las predicciones del algoritmo. Pero eso se debe realizar al final de todo)__\n",
    "\n",
    "##### Dividiendo al set de entrenamiento\n",
    "\n",
    "__Bootstrapping:__\n",
    "\n",
    "1. Tomamos n muestras del set de entrenamiento (con reemplazo, el dato puede repetirse) y corremos el algoritmo para esas n muestras.\n",
    "2. Con esto generamos n modelos distintos.\n",
    "3. Luego corremos el set de testing con esos n modelos, y llegamos a un resultado por votación (promediando).\n",
    "\n",
    "La técnica de bagging disminuye la posibilidad de overfitting\n",
    "\n",
    "Como cada clasificador no ve la totalidad de los registros del set de entrenamiento ninguno de los n clasificadores individuales puede sobre-ajustar.\n",
    "\n",
    "Registros OOB (Out of Bag), es decir fuera del bagging se usan para ver la precisión del algoritmo. (como se fuera de un set de validación).\n",
    "\n",
    "Promedio de precisión de los registros OOB se puede usar para analizar la precisión del ensamble entero, y obtener los mejores hiper-parámetros.\n",
    "\n",
    "__k-fold Cross Validation:__\n",
    "\n",
    "1. Dividir la muestra en k conjuntos \n",
    "2. Para i = 1..k: entrenar en todos menos i-ésimo conjunto, validar sobre el i-ésimo conjunto \n",
    "3. Performance: promedio de las k iteraciones\n",
    "    \n",
    "Esto nos permite comparar la performance de distintos modelos para nuestro set de datos, fijar parametros de ajuste, etc.\n",
    "\n",
    ">__Luego de definido el modelo, podemos entrenarlo con nuestro set de entrenamiento completo.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Datos a filtrar\n",
    "\n",
    "(Acá ejecutamos lo planeado en __Sets de Datos__) -mk\n",
    "\n",
    "Hechemos un vistazo del set de datos.\n",
    "\n",
    "Para manejar y visualizar los datos, utilizamos *pandas*.\n",
    "\n",
    "(Si tienen/quieren otras alternativas, sugieran :D . El set de test, __creo__ yo que no se debe __tocar__ en tanto a eliminar datos o corregirlos. Cómo actúa el algoritmo en situaciones que no conoce?) -mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', low_memory=False)\n",
    "test = pd.read_csv('./data/test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos los sets de datos\n",
    "print float(train.shape[0] / test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En principio, los datos de entrenamiento son 4 veces mayores a los de testeo.\n",
    "\n",
    "Algo importante de notar de esto, es que cuando el algoritmo de predicción esté armado y preparado, los datos que ingresaremos serán los de testeo. Digo esto porque, si el algoritmo aprende a predecir duración en función de distancias, deberá tener en cuenta que primero se debe calcular la distancia entre las estaciones (ya no es parte del dato de prueba en sí).\n",
    "\n",
    "> Los nombres de las estaciones no son necesarios ya que se conocen sus identificaciones.\n",
    "\n",
    "> El tipo de suscripción se puede convertir a un número. Además sólo hay dos tipos de suscripción.\n",
    "\n",
    "> Las identificaciones de los viajes tampoco son necesarias ya que no aportan informacion útil. (Al menos a mí no me parece obvio) -mk\n",
    "\n",
    "> (Zip-code, en este caso no me acuerdo que era, pero creo se puede sacar. Además, hay algunos datos con NaN)\n",
    "\n",
    "(El set de testeo (creo) que __NO__ se debe tocar (en cuanto a valores NaN y eso) aunque si el formato de fechas, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cambiamos los nombres de los features, para que sea mas facil de leer\n",
    "renombres = {'subscription_type': 'sub_type',\n",
    "             'start_station_name': 'ss_name',\n",
    "             'end_station_name': 'es_name',\n",
    "             'start_station_id': 'ss_id',\n",
    "             'end_station_id': 'es_id',\n",
    "             'start_date': 's_date',\n",
    "             'end_date': 'e_date',\n",
    "             'zip_code': 'z_code',\n",
    "             'bike_id': 'b_id'}\n",
    "\n",
    "train.rename(columns=renombres, inplace=True)\n",
    "test.rename(columns=renombres, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convirtiendo el formato de fecha\n",
    "# el parametro 'format' hace que se ejecute un poco mas rapido\n",
    "train.s_date = pd.to_datetime(train.s_date, format='%m/%d/%Y %H:%M')\n",
    "train.e_date = pd.to_datetime(train.e_date, format='%m/%d/%Y %H:%M')\n",
    "test.s_date = pd.to_datetime(test.s_date, format='%m/%d/%Y %H:%M')\n",
    "test.e_date = pd.to_datetime(test.e_date, format='%m/%d/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quitamos los datos invalidos\n",
    "# (los NaN y eso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quitamos las columnas ss_name y es_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de continuar a la siguiente sección, vemos como es la relación entre los sets de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos los sets de datos luego de filtrarlos\n",
    "print float(train.shape[0] / test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Modelo\n",
    "\n",
    "Finalmente, luego de realizar las consideraciones, en esta sección armamos el modelo que resuelva el problema de predicción.\n",
    "\n",
    "*plan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Ejecución del modelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
