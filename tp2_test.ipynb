{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = {'San Francisco':1,'San Jose':2,'Mountain View':3,'Palo Alto':4,'Redwood City':5}\n",
    "def ciudades(ciudad):\n",
    "    return cities[ciudad]\n",
    "\n",
    "# Funcion para convertir el tipo de subscripcion\n",
    "def sub_type(sub):\n",
    "    if sub == 'Customer': return 1\n",
    "    return 0\n",
    "\n",
    "events = {'Normal': 0 , 'Fog': 1 , 'Rain': 2 , 'Fog-Rain': 3 , 'Rain-Thunderstorm': 4}\n",
    "def eventos(event):\n",
    "    return events[event]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nombres = {'subscription_type':  'sub_type',\n",
    "           'start_station_name': 'ss_name',\n",
    "           'end_station_name':   'es_name',\n",
    "           'start_station_id':   'sid',\n",
    "           'end_station_id':     'es_id',\n",
    "           'start_date':         's_date',\n",
    "           'end_date':           'e_date',\n",
    "           'zip_code':           'z_code',\n",
    "           'bike_id':            'b_id'}\n",
    "\n",
    "train.rename(columns=nombres, inplace=True)\n",
    "\n",
    "train.drop(['ss_name', 'es_name', 'z_code', 'id','e_date','es_id'], axis=1, inplace=True)\n",
    "train.rename(columns={'sid':'id'}, inplace=True)\n",
    "\n",
    "train['s_date'] = pd.to_datetime(train['s_date'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "train['year'] = train['s_date'].map(lambda x:x.year)\n",
    "train['month'] = train['s_date'].map(lambda x:x.month)\n",
    "train['day'] = train['s_date'].map(lambda x:x.day)\n",
    "train['weekday'] = train['s_date'].map(lambda x: x.weekday())\n",
    "train['hour'] = train['s_date'].map(lambda x:x.hour)\n",
    "train['minute'] = train['s_date'].map(lambda x:x.minute)\n",
    "\n",
    "train['date'] = pd.DatetimeIndex(train['s_date']).normalize()\n",
    "\n",
    "train = train.merge(pd.get_dummies(train.sub_type), left_index=True, right_index=True)\n",
    "train.drop('sub_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[train.duration <= 21600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stations = pd.read_csv('./data/station.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations = stations.merge(pd.get_dummies(stations.city), left_index=True, right_index=True)\n",
    "stations.drop(['name','lat','long','installation_date','city'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv('./data/weather.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rename = {'max_temperature_f': 'max_temp', \n",
    "          'mean_temperature_f': 'mean_temp', \n",
    "          'min_temperature_f': 'min_temp', \n",
    "          'max_dew_point_f': 'max_dew', \n",
    "          'mean_dew_point_f': 'mean_dew', \n",
    "          'min_dew_point_f': 'min_dew', \n",
    "          'max_humidity': 'max_hum', \n",
    "          'mean_humidity': 'mean_hum', \n",
    "          'min_humidity': 'min_hum', \n",
    "          'max_sea_level_pressure_inches': 'max_slp', \n",
    "          'mean_sea_level_pressure_inches': 'mean_slp', \n",
    "          'min_sea_level_pressure_inches': 'min_slp', \n",
    "          'max_visibility_miles': 'max_vis', \n",
    "          'mean_visibility_miles': 'mean_vis', \n",
    "          'min_visibility_miles': 'min_vis', \n",
    "          'max_wind_Speed_mph': 'max_wind', \n",
    "          'mean_wind_speed_mph': 'mean_wind', \n",
    "          'max_gust_speed_mph': 'max_gust', \n",
    "          'precipitation_inches': 'precipitation', \n",
    "          'cloud_cover': 'cloud', \n",
    "          'wind_dir_degrees': 'wind_dir', \n",
    "          'zip_code': 'z_code'\n",
    "         }\n",
    "\n",
    "weather.rename(columns=rename, inplace=True)\n",
    "\n",
    "weather['date'] = pd.to_datetime(weather['date'], format='%m/%d/%Y')\n",
    "weather.loc[weather.events == 'rain', 'events'] = 'Rain'\n",
    "weather.loc[weather.events.isnull(), 'events'] = 'Normal'\n",
    "weather = weather.merge(pd.get_dummies(weather.events), left_index=True, right_index=True)\n",
    "#weather.events = weather.events.map(lambda x: events(x))\n",
    "\n",
    "weather.loc[weather.precipitation == 'T', 'precipitation'] = 0\n",
    "weather.precipitation = weather.precipitation.astype(np.float64)\n",
    "\n",
    "for i in weather:\n",
    "    weather.drop(weather.loc[weather[i].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(train, stations, how='right', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547395, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, weather, how='right', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2035506, 47)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['s_date','date','events'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration             0\n",
       "id                   0\n",
       "b_id                 0\n",
       "year                 0\n",
       "month                0\n",
       "day                  0\n",
       "weekday              0\n",
       "hour                 0\n",
       "minute               0\n",
       "Customer             0\n",
       "Subscriber           0\n",
       "dock_count           0\n",
       "Mountain View        0\n",
       "Palo Alto            0\n",
       "Redwood City         0\n",
       "San Francisco        0\n",
       "San Jose             0\n",
       "max_temp             0\n",
       "mean_temp            0\n",
       "min_temp             0\n",
       "max_dew              0\n",
       "mean_dew             0\n",
       "min_dew              0\n",
       "max_hum              0\n",
       "mean_hum             0\n",
       "min_hum              0\n",
       "max_slp              0\n",
       "mean_slp             0\n",
       "min_slp              0\n",
       "max_vis              0\n",
       "mean_vis             0\n",
       "min_vis              0\n",
       "max_wind             0\n",
       "mean_wind            0\n",
       "max_gust             0\n",
       "precipitation        0\n",
       "cloud                0\n",
       "wind_dir             0\n",
       "z_code               0\n",
       "Fog                  0\n",
       "Fog-Rain             0\n",
       "Normal               0\n",
       "Rain                 0\n",
       "Rain-Thunderstorm    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "Y = df.duration.values\n",
    "df = normalize(df.drop(['duration'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk/p2env/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "#from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import * \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[:1000]\n",
    "y = Y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrandientBoosting 3558784.77579\n",
      "RANSAC            200404640936.0\n",
      "RandomForest      3481778.1345\n",
      "ARD               3689569.58531\n",
      "SGD               3690041.98287\n",
      "PassiveAggressive 3749869.89779\n",
      "DecisionTree      2092393.92\n",
      "TheilSen          3564378.39385\n",
      "AdaBoost          3729020.82413\n",
      "KernelRidge       3689734.05241\n",
      "Bagging           2905468.28285\n",
      "Linear            3512080.5393\n",
      "GaussianProcess   3515935.05244\n",
      "ExtraTrees        2718297.32515\n",
      "Logistic          3722314.815\n",
      "Huber             3735942.7178\n"
     ]
    }
   ],
   "source": [
    "regs = {AdaBoostRegressor():'AdaBoost         ',\n",
    "BaggingRegressor():'Bagging          ',\n",
    "ExtraTreesRegressor():'ExtraTrees       ',\n",
    "GradientBoostingRegressor():'GrandientBoosting',\n",
    "RandomForestRegressor():'RandomForest     ',\n",
    "DecisionTreeRegressor():'DecisionTree     ',\n",
    "ARDRegression():'ARD              ',\n",
    "HuberRegressor():'Huber            ',\n",
    "LinearRegression():'Linear           ',\n",
    "LogisticRegression():'Logistic         ',\n",
    "PassiveAggressiveRegressor():'PassiveAggressive',\n",
    "RANSACRegressor():'RANSAC           ',\n",
    "SGDRegressor():'SGD              ',\n",
    "TheilSenRegressor():'TheilSen         ',\n",
    "KernelRidge():'KernelRidge      ',\n",
    "GaussianProcessRegressor():'GaussianProcess  '}\n",
    "\n",
    "for reg in regs:\n",
    "    reg.fit(X_train, y_train)\n",
    "    print regs[reg],mse(reg.predict(X_test), y_test)#,'\\t ', reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.0715739727\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print end-start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
